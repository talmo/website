---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Fast animal pose estimation using deep neural networks
subtitle: ''
summary: ''
authors:
- Talmo D Pereira
- Diego E Aldarondo
- Lindsay Willmore
- Mikhail Kislin
- Samuel S-H Wang
- Mala Murthy
- Joshua W Shaevitz
tags: []
categories: []
date: '2019-01-01'
lastmod: 2020-10-12T13:11:41-04:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2020-10-12T17:11:40.714904Z'
publication_types:
- '2'
abstract: The need for automated and efficient systems for tracking full animal pose
  has increased with the complexity of behavioral data and analyses. Here we introduce
  LEAP (LEAP estimates animal pose), a deep-learning-based method for predicting the
  positions of animal body parts. This framework consists of a graphical interface
  for labeling of body parts and training the network. LEAP offers fast prediction
  on new data, and training with as few as 100 frames results in 95% of peak performance.
  We validated LEAP using videos of freely behaving fruit flies and tracked 32 distinct
  points to describe the pose of the head, body, wings and legs, with an error rate
  of <3% of body length. We recapitulated reported findings on insect gait dynamics
  and demonstrated LEAP's applicability for unsupervised behavioral classification.
  Finally, we extended the method to more challenging imaging situations and videos
  of freely moving mice.
publication: '*Nat. Methods*'
---
