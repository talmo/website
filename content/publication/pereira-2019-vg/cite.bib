@article{Pereira2019-vg,
 abstract = {The need for automated and efficient systems for tracking full
animal pose has increased with the complexity of behavioral data
and analyses. Here we introduce LEAP (LEAP estimates animal
pose), a deep-learning-based method for predicting the positions
of animal body parts. This framework consists of a graphical
interface for labeling of body parts and training the network.
LEAP offers fast prediction on new data, and training with as few
as 100 frames results in 95% of peak performance. We validated
LEAP using videos of freely behaving fruit flies and tracked 32
distinct points to describe the pose of the head, body, wings and
legs, with an error rate of <3% of body length. We recapitulated
reported findings on insect gait dynamics and demonstrated LEAP's
applicability for unsupervised behavioral classification.
Finally, we extended the method to more challenging imaging
situations and videos of freely moving mice.},
 author = {Pereira, Talmo D and Aldarondo, Diego E and Willmore, Lindsay and
Kislin, Mikhail and Wang, Samuel S-H and Murthy, Mala and
Shaevitz, Joshua W},
 journal = {Nat. Methods},
 language = {en},
 month = {January},
 number = {1},
 pages = {117--125},
 title = {Fast animal pose estimation using deep neural networks},
 volume = {16},
 year = {2019}
}

