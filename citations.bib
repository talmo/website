@ARTICLE{Hobbs2016-bm,
  title    = "A Bayesian inference method for the analysis of transcriptional
              regulatory networks in metagenomic data",
  author   = "Hobbs, Elizabeth T and Pereira, Talmo and O'Neill, Patrick K and
              Erill, Ivan",
  abstract = "BACKGROUND: Metagenomics enables the analysis of bacterial
              population composition and the study of emergent population
              features, such as shared metabolic pathways. Recently, we have
              shown that metagenomics datasets can be leveraged to characterize
              population-wide transcriptional regulatory networks, or
              meta-regulons, providing insights into how bacterial populations
              respond collectively to specific triggers. Here we formalize a
              Bayesian inference framework to analyze the composition of
              transcriptional regulatory networks in metagenomes by determining
              the probability of regulation of orthologous gene sequences. We
              assess the performance of this approach on synthetic datasets and
              we validate it by analyzing the copper-homeostasis network of
              Firmicutes species in the human gut microbiome. RESULTS:
              Assessment on synthetic datasets shows that our method provides a
              robust and interpretable metric for assessing putative regulation
              by a transcription factor on sets of promoter sequences mapping
              to an orthologous gene cluster. The inference framework
              integrates the regulatory contribution of secondary sites and can
              discern false positives arising from multiple instances of a
              clonal sequence. Posterior probabilities for orthologous gene
              clusters decline sharply when less than 20 \% of mapped promoters
              have binding sites, but we introduce a sensitivity adjustment
              procedure to speed up computation that enhances regulation
              assessment in heterogeneous ortholog clusters. Analysis of the
              copper-homeostasis regulon governed by CsoR in the human gut
              microbiome Firmicutes reveals that CsoR controls itself and
              copper-translocating P-type ATPases, but not CopZ-type copper
              chaperones. Our analysis also indicates that CsoR frequently
              targets promoters with dual CsoR-binding sites, suggesting that
              it exploits higher-order binding conformations to fine-tune its
              activity. CONCLUSIONS: We introduce and validate a method for the
              analysis of transcriptional regulatory networks from metagenomic
              data that enables inference of meta-regulons in a systematic and
              interpretable way. Validation of this method on the CsoR
              meta-regulon of gut microbiome Firmicutes illustrates the
              usefulness of the approach, revealing novel properties of the
              copper-homeostasis network in poorly characterized bacterial
              species and putting forward evidence of new mechanisms of DNA
              binding for this transcriptional regulator. Our approach will
              enable the comparative analysis of regulatory networks across
              metagenomes, yielding novel insights into the evolution of
              transcriptional regulatory networks.",
  journal  = "Algorithms Mol. Biol.",
  volume   =  11,
  pages    = "19",
  month    =  jul,
  year     =  2016,
  keywords = "Bayesian inference; Copper homeostasis; CsoR; Metagenomics; Metal
              resistance; Regulatory network; Regulon; Stress response;
              Transcription factor",
  language = "en"
}

@ARTICLE{Giovannucci2017-xt,
  title    = "Cerebellar granule cells acquire a widespread predictive feedback
              signal during motor learning",
  author   = "Giovannucci, Andrea and Badura, Aleksandra and Deverett, Ben and
              Najafi, Farzaneh and Pereira, Talmo D and Gao, Zhenyu and Ozden,
              Ilker and Kloth, Alexander D and Pnevmatikakis, Eftychios and
              Paninski, Liam and De Zeeuw, Chris I and Medina, Javier F and
              Wang, Samuel S-H",
  abstract = "Cerebellar granule cells, which constitute half the brain's
              neurons, supply Purkinje cells with contextual information
              necessary for motor learning, but how they encode this
              information is unknown. Here we show, using two-photon microscopy
              to track neural activity over multiple days of
              cerebellum-dependent eyeblink conditioning in mice, that granule
              cell populations acquire a dense representation of the
              anticipatory eyelid movement. Initially, granule cells responded
              to neutral visual and somatosensory stimuli as well as
              periorbital airpuffs used for training. As learning progressed,
              two-thirds of monitored granule cells acquired a conditional
              response whose timing matched or preceded the learned eyelid
              movements. Granule cell activity covaried trial by trial to form
              a redundant code. Many granule cells were also active during
              movements of nearby body structures. Thus, a predictive signal
              about the upcoming movement is widely available at the input
              stage of the cerebellar cortex, as required by forward models of
              cerebellar control.",
  journal  = "Nat. Neurosci.",
  volume   =  20,
  number   =  5,
  pages    = "727--734",
  month    =  may,
  year     =  2017,
  language = "en"
}

@ARTICLE{Giovannucci2018-vb,
  title    = "Automated gesture tracking in head-fixed mice",
  author   = "Giovannucci, A and Pnevmatikakis, E A and Deverett, B and
              Pereira, T and Fondriest, J and Brady, M J and Wang, S S-H and
              Abbas, W and Par{\'e}s, P and Masip, D",
  abstract = "BACKGROUND: The preparation consisting of a head-fixed mouse on a
              spherical or cylindrical treadmill offers unique advantages in a
              variety of experimental contexts. Head fixation provides the
              mechanical stability necessary for optical and
              electrophysiological recordings and stimulation. Additionally, it
              can be combined with virtual environments such as T-mazes,
              enabling these types of recording during diverse behaviors. NEW
              METHOD: In this paper we present a low-cost, easy-to-build
              acquisition system, along with scalable computational methods to
              quantitatively measure behavior (locomotion and paws, whiskers,
              and tail motion patterns) in head-fixed mice locomoting on
              cylindrical or spherical treadmills. EXISTING METHODS: Several
              custom supervised and unsupervised methods have been developed
              for measuring behavior in mice. However, to date there is no
              low-cost, turn-key, general-purpose, and scalable system for
              acquiring and quantifying behavior in mice. RESULTS: We benchmark
              our algorithms against ground truth data generated either by
              manual labeling or by simpler methods of feature extraction. We
              demonstrate that our algorithms achieve good performance, both in
              supervised and unsupervised settings. CONCLUSIONS: We present a
              low-cost suite of tools for behavioral quantification, which
              serve as valuable complements to recording and stimulation
              technologies being developed for the head-fixed mouse
              preparation.",
  journal  = "J. Neurosci. Methods",
  volume   =  300,
  pages    = "184--195",
  month    =  apr,
  year     =  2018,
  keywords = "Behavior; Head-fixed; Tracking",
  language = "en"
}

@ARTICLE{Pereira2017-de,
  title     = "To Fight or Not to Fight",
  author    = "Pereira, Talmo D and Murthy, Mala",
  abstract  = "In this issue of Neuron, Watanabe et al. (2017) uncover how
               octopamine, an invertebrate norepinephrine analog, modulates the
               neural pathways that bias Drosophila males toward aggression.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  95,
  number    =  5,
  pages     = "986--988",
  month     =  aug,
  year      =  2017
}

@ARTICLE{Clemens2018-db,
  title    = "Discovery of a New Song Mode in Drosophila Reveals Hidden
              Structure in the Sensory and Neural Drivers of Behavior",
  author   = "Clemens, Jan and Coen, Philip and Roemschied, Frederic A and
              Pereira, Talmo D and Mazumder, David and Aldarondo, Diego E and
              Pacheco, Diego A and Murthy, Mala",
  abstract = "Deciphering how brains generate behavior depends critically on an
              accurate description of behavior. If distinct behaviors are
              lumped together, separate modes of brain activity can be wrongly
              attributed to the same behavior. Alternatively, if a single
              behavior is split into two, the same neural activity can appear
              to produce different behaviors. Here, we address this issue in
              the context of acoustic communication in Drosophila. During
              courtship, males vibrate their wings to generate time-varying
              songs, and females evaluate songs to inform mating decisions. For
              50 years, Drosophila melanogaster song was thought to consist of
              only two modes, sine and pulse, but using unsupervised
              classification methods on large datasets of song recordings, we
              now establish the existence of at least three song modes: two
              distinct pulse types, along with a single sine mode. We show how
              this seemingly subtle distinction affects our interpretation of
              the mechanisms underlying song production and perception.
              Specifically, we show that visual feedback influences the
              probability of producing each song mode and that male song mode
              choice affects female responses and contributes to modulating his
              song amplitude with distance. At the neural level, we demonstrate
              how the activity of four separate neuron types within the fly's
              song pathway differentially affects the probability of producing
              each song mode. Our results highlight the importance of carefully
              segmenting behavior to map the underlying sensory, neural, and
              genetic mechanisms.",
  journal  = "Curr. Biol.",
  volume   =  28,
  number   =  15,
  pages    = "2400--2412.e6",
  month    =  aug,
  year     =  2018,
  keywords = "Drosophila; acoustic communication; behavior; courtship song;
              neural circuits",
  language = "en"
}

@ARTICLE{Badura2018-ge,
  title    = "Normal cognitive and social development require posterior
              cerebellar activity",
  author   = "Badura, Aleksandra and Verpeut, Jessica L and Metzger, Julia W
              and Pereira, Talmo D and Pisano, Thomas J and Deverett, Ben and
              Bakshinskaya, Dariya E and Wang, Samuel S-H",
  abstract = "Cognitive and social capacities require postnatal experience, yet
              the pathways by which experience guides development are unknown.
              Here we show that the normal development of motor and nonmotor
              capacities requires cerebellar activity. Using chemogenetic
              perturbation of molecular layer interneurons to attenuate
              cerebellar output in mice, we found that activity of posterior
              regions in juvenile life modulates adult expression of eyeblink
              conditioning (paravermal lobule VI, crus I), reversal learning
              (lobule VI), persistive behavior and novelty-seeking (lobule
              VII), and social preference (crus I/II). Perturbation in adult
              life altered only a subset of phenotypes. Both adult and juvenile
              disruption left gait metrics largely unaffected. Contributions to
              phenotypes increased with the amount of lobule inactivated. Using
              an anterograde transsynaptic tracer, we found that posterior
              cerebellum made strong connections with prelimbic, orbitofrontal,
              and anterior cingulate cortex. These findings provide anatomical
              substrates for the clinical observation that cerebellar injury
              increases the risk of autism.",
  journal  = "Elife",
  volume   =  7,
  month    =  sep,
  year     =  2018,
  keywords = "cerebellum; chemogenetic; cognitive; development; flexible
              behavior; mouse; neuroscience; transsynaptic",
  language = "en"
}

@INPROCEEDINGS{Hermsdorff2018-bn,
  title     = "Quantifying Humans' Priors Over Graphical Representations of
               Tasks",
  booktitle = "International Conference on Complex Systems",
  author    = "Hermsdorff, Gecia Bravo and Pereira, Talmo and Niv, Yael",
  abstract  = "Some new tasks are trivial to learn while others are almost
               impossible; what determines how easy it is to learn an arbitrary
               task? Similar to how our prior beliefs about new visual scenes
               colors our perception of new stimuli, our priors about the
               structure of new tasks shapes our learning and generalization
               abilities [2]. While quantifying visual priors has led to major
               insights on how our visual system works [5, 10, 11], quantifying
               priors over tasks remains a formidable goal, as it is not even
               clear how to define a task [4]. Here, we focus on tasks that
               have a natural mapping to graphs. We develop a method to
               quantify humans' priors over these ``task graphs'', combining
               new modeling approaches with Markov chain Monte Carlo with
               people, MCMCP (a process whereby an agent learns from data
               generated by another agent, recursively [9]). We show that our
               method recovers priors more accurately than a standard MCMC
               sampling approach. Additionally, we propose a novel
               low-dimensional ``smooth'' (In the sense that graphs that differ
               by fewer edges are given similar probabilities.) parametrization
               of probability distributions over graphs that allows for more
               accurate recovery of the prior and better generalization. We
               have also created an online experiment platform that gamifies
               our MCMCP algorithm and allows subjects to interactively draw
               the task graphs. We use this platform to collect human data on
               several navigation and social interactions tasks. We show that
               priors over these tasks have non-trivial structure, deviating
               significantly from null models that are insensitive to the
               graphical information. The priors also notably differ between
               the navigation and social domains, showing fewer differences
               between cover stories within the same domain. Finally, we extend
               our framework to the more general case of quantifying priors
               over exchangeable random structures.",
  publisher = "Springer International Publishing",
  pages     = "281--290",
  month     =  jul,
  year      =  2018
}

@ARTICLE{Pereira2019-vg,
  title    = "Fast animal pose estimation using deep neural networks",
  author   = "Pereira, Talmo D and Aldarondo, Diego E and Willmore, Lindsay and
              Kislin, Mikhail and Wang, Samuel S-H and Murthy, Mala and
              Shaevitz, Joshua W",
  abstract = "The need for automated and efficient systems for tracking full
              animal pose has increased with the complexity of behavioral data
              and analyses. Here we introduce LEAP (LEAP estimates animal
              pose), a deep-learning-based method for predicting the positions
              of animal body parts. This framework consists of a graphical
              interface for labeling of body parts and training the network.
              LEAP offers fast prediction on new data, and training with as few
              as 100 frames results in 95\% of peak performance. We validated
              LEAP using videos of freely behaving fruit flies and tracked 32
              distinct points to describe the pose of the head, body, wings and
              legs, with an error rate of <3\% of body length. We recapitulated
              reported findings on insect gait dynamics and demonstrated LEAP's
              applicability for unsupervised behavioral classification.
              Finally, we extended the method to more challenging imaging
              situations and videos of freely moving mice.",
  journal  = "Nat. Methods",
  volume   =  16,
  number   =  1,
  pages    = "117--125",
  month    =  jan,
  year     =  2019,
  language = "en"
}

@UNPUBLISHED{Deutsch2020-by,
  title    = "The Neural Basis for a Persistent Internal State in Drosophila
              Females",
  author   = "Deutsch, David and Pacheco, Diego A and Encarnacion-Rivera, Lucas
              J and Pereira, Talmo and Fathy, Ramie and Calhoun, Adam and
              Ireland, Elise C and Burke, Austin T and Dorkenwald, Sven and
              McKellar, Claire and Macrina, Thomas and Lu, Ran and Lee, Kisuk
              and Kemnitz, Nico and Ih, Dodam and Castro, Manuel and Halageri,
              Akhilesh and Jordan, Chris and Silversmith, William and Wu,
              Jingpeng and Sebastian Seung, H and Murthy, Mala",
  abstract = "Abstract Sustained changes in mood or action require persistent
              changes in neural activity, but it has been difficult to identify
              and characterize the neural circuit mechanisms that underlie
              persistent activity and contribute to long-lasting changes in
              behavior. Here, we focus on changes in the behavioral state of
              Drosophila females that persist for minutes following optogenetic
              activation of a single class of central brain neurons termed pC1.
              We find that female pC1 neurons drive a variety of persistent
              behaviors in the presence of males, including increased
              receptivity, shoving, and chasing. By reconstructing cells in a
              volume electron microscopic image of the female brain, we
              classify 7 different pC1 cell types and, using cell type specific
              driver lines, determine that one of these, pC1-Alpha, is
              responsible for driving persistent female shoving and chasing.
              Using calcium imaging, we locate sites of minutes-long persistent
              neural activity in the brain, which include pC1 neurons
              themselves. Finally, we exhaustively reconstruct all synaptic
              partners of a single pC1-Alpha neuron, and find recurrent
              connectivity that could support the persistent neural activity.
              Our work thus links minutes-long persistent changes in behavior
              with persistent neural activity and recurrent circuit
              architecture in the female brain.",
  journal  = "bioRxiv",
  pages    = "2020.02.13.947952",
  month    =  feb,
  year     =  2020,
  language = "en"
}

@ARTICLE{Charles2020-eo,
  title    = "Toward {Community-Driven} Big Open Brain Science: Open Big Data
              and Tools for Structure, Function, and Genetics",
  author   = "Charles, Adam S and Falk, Benjamin and Turner, Nicholas and
              Pereira, Talmo D and Tward, Daniel and Pedigo, Benjamin D and
              Chung, Jaewon and Burns, Randal and Ghosh, Satrajit S and
              Kebschull, Justus M and Silversmith, William and Vogelstein,
              Joshua T",
  abstract = "As acquiring bigger data becomes easier in experimental brain
              science, computational and statistical brain science must achieve
              similar advances to fully capitalize on these data. Tackling
              these problems will benefit from a more explicit and concerted
              effort to work together. Specifically, brain science can be
              further democratized by harnessing the power of community-driven
              tools, which both are built by and benefit from many different
              people with different backgrounds and expertise. This perspective
              can be applied across modalities and scales and enables
              collaborations across previously siloed communities.",
  journal  = "Annu. Rev. Neurosci.",
  volume   =  43,
  pages    = "441--464",
  month    =  jul,
  year     =  2020,
  keywords = "computational; infrastructure; reference data; statistics",
  language = "en"
}

@article{Princeton_Open_Ventilation_Monitor_Collaboration2020-hn,
  title       = "Inexpensive multi-patient respiratory monitoring system for
                 helmet ventilation during {COVID-19} pandemic",
  author      = "{Princeton Open Ventilation Monitor Collaboration} and
                 Bourrianne, Philippe and Chidzik, Stanley and Cohen, Daniel J
                 and Elmer, Peter and Hallowell, Thomas and Kilbaugh, Todd J
                 and Lange, David and Leifer, Andrew M and Marlow, Daniel R and
                 Meyers, Peter D and Normand, Edna and Nunes, Janine and Oh,
                 Myungchul and Page, Lyman and Pereira, Talmo and Pivarski, Jim
                 and Schreiner, Henry and Stone, Howard A and Tank, David W and
                 Thiberge, Stephan and Tully, Christopher",
  abstract    = "Helmet non-invasive ventilation (NIV) is a form of continuous
                 positive applied pressure that has emerged as a useful therapy
                 for COVID-19 patients who require respiratory support but may
                 not require invasive ventilation. Helmet NIV has seen an
                 increase in use during the COVID-19 pandemic because it is
                 low-cost, readily available, and provides viral filters
                 between the patient and clinician. Helmet NIV may also provide
                 better patient outcomes by delaying or eliminating the need
                 for invasive ventilation. Its widespread adoption has been
                 limited, however, by the lack of a respiratory monitoring
                 system that is needed to address known safety vulnerabilities
                 and to provide clinicians with a respiratory profile of the
                 patient. To address this safety need, we have developed an
                 inexpensive respiratory monitoring system that is based on
                 readily available commercial components and is suitable for
                 rapid local manufacture. The system is designed for use in
                 conjunction with the COVID-19 Helmet developed by Sea-Long
                 Medical Systems, but is modular and can be used with other
                 ventilation systems. The monitoring system comprises one or
                 more flow and pressure sensors and a central remote station
                 that can be used to remotely monitor up to 20 patients
                 simultaneously. The system reports flow, pressure, and
                 clinically relevant metrics including respiratory rate, tidal
                 volume equivalent, peak inspiratory pressure (PIP), positive
                 end-expiratory pressure (PEEP) and the ratio of inspiratory
                 time to expiratory time (I:E). The device will sound alarms
                 based on clinician-set thresholds. In bench tests using a
                 commercial ventilator and artificial lung system, our device
                 performs comparably to a commercial single-patient respiratory
                 monitor. Results are presented from human-subject tests on a
                 healthy volunteer undergoing helmet non-invasive ventilation.
                 Detailed design and manufacturing documents are provided.",
  journal     = "Intensive Care and Critical Care Medicine",
  number      = "medrxiv;2020.06.29.20141283v1",
  institution = "medRxiv",
  month       =  jun,
  year        =  2020
}

@article{Jones2020-ts,
  title    = "A machine-vision approach for automated pain measurement at
              millisecond timescales",
  author   = "Jones, Jessica M and Foster, William and Twomey, Colin R and
              Burdge, Justin and Ahmed, Osama M and Pereira, Talmo D and
              Wojick, Jessica A and Corder, Gregory and Plotkin, Joshua B and
              Abdus-Saboor, Ishmail",
  abstract = "Objective and automatic measurement of pain in mice remains a
              barrier for discovery in neuroscience. Here, we capture paw
              kinematics during pain behavior in mice with high-speed
              videography and automated paw tracking with machine and deep
              learning approaches. Our statistical software platform, PAWS
              (Pain Assessment at Withdrawal Speeds), uses a univariate
              projection of paw position over time to automatically quantify
              seven behavioral features that are combined into a single,
              univariate pain score. Automated paw tracking combined with PAWS
              reveals a behaviorally divergent mouse strain that displays
              hypersensitivity to mechanical stimuli. To demonstrate the
              efficacy of PAWS for detecting spinally versus centrally mediated
              behavioral responses, we chemogenetically activated nociceptive
              neurons in the amygdala, which further separated the pain-related
              behavioral features and the resulting pain score. Taken together,
              this automated pain quantification approach will increase
              objectivity in collecting rigorous behavioral data, and it is
              compatible with other neural circuit dissection tools for
              determining the mouse pain state.",
  journal  = "Elife",
  volume   =  9,
  month    =  aug,
  year     =  2020,
  keywords = "automation; high-speed videography; machine learning; mouse;
              neural circuits; neuroscience; pain; somatosensation",
  language = "en"
}

@article{Pereira2020-tt,
  title    = "{SLEAP}: Multi-animal pose tracking",
  author   = "Pereira, Talmo D and Tabris, Nathaniel and Li, Junyu and
              Ravindranath, Shruthi and Papadoyannis, Eleni S and Yan Wang, Z
              and Turner, David M and McKenzie-Smith, Grace and Kocher, Sarah D
              and Falkner, Annegret Lea and Shaevitz, Joshua W and Murthy, Mala",
  abstract = "The desire to understand how the brain generates and patterns
              behavior has driven rapid methodological innovation to quantify
              and model natural animal behavior. This has led to important
              advances in deep learning-based markerless pose estimation that
              have been enabled in part by the success of deep learning for
              computer vision applications. Here we present SLEAP (Social LEAP
              Estimates Animal Poses), a framework for multi-animal pose
              tracking via deep learning. This system is capable of
              simultaneously tracking any number of animals during social
              interactions and across a variety of experimental conditions.
              SLEAP implements several complementary approaches for dealing
              with the problems inherent in moving from single- to multi-animal
              pose tracking, including configurable neural network
              architectures, inference techniques, and tracking algorithms,
              enabling easy specialization and tuning for particular
              experimental conditions or performance requirements. We report
              results on multiple datasets of socially interacting animals
              (flies, bees, and mice) and describe how dataset-specific
              properties can be leveraged to determine the best configuration
              of SLEAP models. Using a high accuracy model (<2.8 px error on
              95\% of points), we were able to track two animals from full size
              1024 x 1024 pixel frames at up to 320 FPS. The SLEAP framework
              comes with a sophisticated graphical user interface,
              multi-platform support, Colab-based GPU-free training and
              inference, and complete tutorials available, in addition to the
              datasets, at sleap.ai. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2020.08.31.276246",
  month    =  sep,
  year     =  2020,
  language = "en"
}

@article{Pereira2020-review,
  title  = "Quantifying behavior to understand the brain",
  author = "Pereira, Talmo D and Shaevitz, Joshua W and Murthy, Mala",
  abstract = "Over the past years, numerous methods have emerged to automate the 
              quantification of animal behavior at a resolution not previously 
              imaginable. This has opened up a new field of computational 
              ethology, and will in the near future make it possible to 
              quantify in near completeness what an animal is doing as it 
              navigates its environment. The importance of improving the 
              techniques with which we characterize behavior is reflected in 
              the emerging recognition that understanding behavior is an 
              essential (or even pre-requisite) step to pursuing neuroscience 
              questions. The use of these methods, however, is not limited to 
              studying behavior in the wild or in strictly ethological 
              settings. The modern tools for behavioral quantification can be 
              applied to the full gamut of approaches that have historically 
              been used to link brain to behavior, from psychophysics to 
              cognitive tasks, augmenting those measurements with rich 
              descriptions of how animals navigate those tasks. Here we review 
              recent technical advances in quantifying behavior, particularly 
              in methods for tracking animal motion and characterizing the 
              structure of those dynamics. We discuss open challenges that 
              remain for behavioral quantification and highlight promising 
              future directions - with a strong emphasis on emerging 
              approaches in deep learning, the core technology that has 
              enabled the markedly rapid pace of progress of this field. We 
              then discuss how quantitative descriptions of behavior can be 
              leveraged to connect brain activity with animal movements, with 
              the ultimate goal of resolving the relationship between neural 
              circuits, cognitive processes, and behavior.",
  journal  = "Nature Neuroscience",
  publisher={Nature Publishing Group},
  volume={In press},
  month    =  dec,
  year   =  "2020"
}
